= Microservicios de RRHH

Este repositorio contiene varios servicios de Spring Boot que conforman el sistema de recursos humanos.

== Requisitos previos

* Se debe tener instalado JDK 17 y disponible en el `PATH`.
* MariaDB tiene que estar corriendo de forma local para los perfiles de desarrollo y producción. Liquibase crea las bases de datos llamadas `contrato`, `empleado`, `entrenamiento`, `nomina`, `consultas` y `orquestador` si no existen.
* Docker y Docker Compose para la infraestructura opcional (Kafka y Zookeeper). Se provee un archivo `compose.yaml`.
* Las pruebas usan la base H2 en memoria, así que no se necesita configuración adicional.

== Compilación y ejecución de los servicios
Cada módulo que representa un servicio posee su propia BDD que se crea al compilar. Sin embargo, hay que tener cuidado con las modificaciones. Existen dos tablas en cada BDD, llamadas databasechangelog y databasechangeloglock, que registran el estado de todas las tablas creadas con Liquibase. Si se producen cambios, se deben actualizar los archivos changelog de definiciones en Liquibase y borrar las TODAS las tablas de la BDD antes de ejecutar una compilación o se generará un error.
Cada módulo de servicio incluye su propio script de Maven Wrapper. Se puede compilar y ejecutar desde un IDE o desde línea de comandos, cuya forma será la que se explicará. En este último caso, navegar al módulo deseado y ejecutar:

[source,bash]
----
./mvnw spring-boot:run
----

Los módulos disponibles son (cada uno incluye su propio `README.adoc` y su versión HTML):

* link:html/comunes_README.html[comunes]
* link:html/servicio-contrato_README.html[servicio-contrato]
* link:html/servicio-empleado_README.html[servicio-empleado]
* link:html/servicio-entrenamiento_README.html[servicio-entrenamiento]
* link:html/servicio-nomina_README.html[servicio-nomina]
* link:html/servicio-orquestador_README.html[servicio-orquestador]
* link:html/servicio-consultas_README.html[servicio-consultas]
* link:html/API-gateway_README.html[API-gateway]
* link:html/servidor-para-descubrimiento_README.html[servidor-para-descubrimiento]
* link:html/servidor-para-monitoreo_README.html[servidor-para-monitoreo]
* link:html/servicio-openapi-ui_README.html[servicio-openapi-ui]

Los enlaces anteriores apuntan a los archivos HTML generados a partir de los
`README.adoc` de cada módulo. Estos documentos se crean únicamente cuando la
compilación se ejecuta con el perfil `docs`. De esa forma evitamos procesar la
documentación en cada build y solo se actualiza cuando realmente es necesario.
Para compilar o ejecutar el conjunto completo con `mvn install` conviene iniciar primero este módulo desde otra terminal:

[source,bash]
----
./mvnw -pl servidor-para-descubrimiento spring-boot:run
----
De esta manera Eureka estará activo y el resto de los servicios podrán registrarse correctamente.
El API Gateway se ejecuta por defecto en el puerto 8080 y distribuye las peticiones hacia los microservicios registrados en Eureka, permitiendo escalar cada servicio con múltiples instancias.

Cada README local describe en detalle las acciones disponibles y muestra los diagramas PlantUML correspondientes.

== Propiedades del proyecto

El `pom.xml` principal define varias versiones compartidas para los módulos. Las
más relevantes son:

* `java.version` -> 17
* `spring-cloud.version` -> 2025.0.0
* `require.maven.version` -> 3.9.9
* `actuator.version` -> 3.5.0

Desde la raíz del repositorio se puede compilar todos los módulos a la vez:

[source,bash]
----
./mvnw clean package
----

=== Actualización de la documentación

Para generar la documentación AsciiDoc de todos los módulos y copiarla a la
interfaz web, activá el perfil `docs` durante la compilación. De esta forma las
páginas HTML se regenerarán solo cuando sea necesario y no en cada build:

[source,bash]
----
./mvnw clean package -Pdocs -s maven-settings.xml
----

El archivo `maven-settings.xml` configura el proxy utilizado
durante la descarga de dependencias. Podés copiarlo a tu `~/.m2/settings.xml`
o pasarlo con la opción `-s` como en el ejemplo.

La conversión de los README se ejecuta en el módulo
`servicio-openapi-ui`. Si ejecutás Maven desde la raíz asegurate de
incluir ese proyecto o, de forma directa, ejecutá:

[source,bash]
----
(cd servicio-openapi-ui && ../mvnw clean package -Pdocs \
    -s ../maven-settings.xml)
----

== Ejecución de pruebas

Ejecutar las pruebas de todos los módulos con:

[source,bash]
----
./mvnw test
----

o dentro de un módulo en particular:

[source,bash]
----
cd servicio-contrato
./mvnw test
----

== Docker Compose

Se incluye una configuración mínima de Docker Compose para levantar Kafka y Zookeeper que requieren los servicios:

[source,bash]
----
docker compose up -d
----

Asegurarse que la instancia local de MariaDB esté corriendo con esas bases de datos creadas durante la compilación, antes de iniciar los servicios. Las pruebas usarán H2 automáticamente.

== Documentación OpenAPI

Cada microservicio expone su especificación OpenAPI en `/v3/api-docs` y una
interfaz Swagger UI en `/swagger-ui.html`. Cuando se ejecutan detrás del API Gateway,
se puede acceder a cada una de ellas a través de rutas como
`http://localhost:8080/<servicio>/v3/api-docs`. Estas URLs estarán disponibles en los
entornos de desarrollo y podrán restringirse cuando se agregue seguridad.

== Postman Tests

En `docs/postman` se incluyen colecciones de Postman de ejemplo. Importar `rrhh-saga-tests.postman_collection.json` en Postman para probar los flujos de creación, actualización, eliminación y estado de la SAGA mediante los endpoints `/api/saga/empleado-contrato`. El archivo `consultas-saga-tests.postman_collection.json` contiene solicitudes adicionales que validan cómo `servicio-consultas` se actualiza luego de cada operación POST, PUT y DELETE. La respuesta del POST inicial guarda los identificadores de empleado y contrato generados en las variables de colección `{{empleadoId}}` y `{{contratoId}}` para que los siguientes pedidos las reutilicen automáticamente. También se provee `crud-tests.postman_collection.json` con ejemplos básicos para ejercitar las operaciones CRUD de todas las entidades de los microservicios. A partir de esta actualización se agregó `nomina-crud-tests.postman_collection.json`, un recorrido simplificado que crea un concepto de liquidación y genera la nómina. Esta colección ahora arranca creando el empleado y su contrato mediante la SAGA para obtener un `empleadoId` válido, asignarle el concepto y generar la nómina verificando que `servicio-consultas` reciba dichas novedades vía Kafka. También se agregó `openapi-tests.postman_collection.json`, una colección que verifica la disponibilidad de la documentación OpenAPI de cada microservicio.
Todas las colecciones asumen que el punto de entrada es el API Gateway disponible en http://localhost:8080.

Para eliminaciones, pasar tanto el id de empleado como el `contratoId` como parámetro de consulta, por ejemplo `DELETE /api/saga/empleado-contrato/5?contratoId=10`.
Usá `GET /api/saga/empleado-contrato/{sagaId}` para inspeccionar el estado de una saga.

Para verificar si se abre el circuit breaker de creación de empleado, hacer varios pedidos fallidos (por ejemplo deteniendo `servicio-empleado`) y luego enviar un `GET` a `http://localhost:8080/actuator/cb-state/crearEmpleadoCB?includeState=true`.
El controlador `CircuitBreakerStatusController` expone de forma explícita el estado de cada breaker en esa URL `/actuator/cb-state/{name}`.

La solicitud `Estado Circuit Breaker crearEmpleadoCB` de la colección de Postman espera que el estado del breaker sea `OPEN`.

Para auditar los intentos de creación de empleado, consultá `GET http://localhost:8080/actuator/cb-state/empleado-actions`.

== Información general de los microservicios

Las responsabilidades de cada módulo y su ubicación principal se detallan a continuación. Se mencionan los patrones de diseño utilizados y la forma en que se comunican entre sí.

* *servicio-empleado* -> se administra el CRUD de empleados en `servicio-empleado/src/main/java`. Se aplican controladores REST, repositorios JPA y mapeos con MapStruct. Cada cambio publica un `EmpleadoEventDto` en Kafka siguiendo el patrón de arquitectura orientada a eventos.
* *servicio-contrato* -> se gestionan los contratos laborales en `servicio-contrato/src/main/java`. Se implementa el patrón Repositorio con Spring Data JPA y se mantienen registros locales de empleados. Se publican eventos contractuales a Kafka para sincronizar el resto del sistema.
* *servicio-entrenamiento* -> se manejan capacitaciones y evaluaciones en `servicio-entrenamiento/src/main/java`. Las operaciones producen y consumen eventos por Kafka aplicando el patrón productor-consumidor.
* *servicio-nomina* -> se realizan cálculos de nómina en `servicio-nomina/src/main/java`. Se notifican los resultados con eventos hacia `servicio-consultas`, aplicando el patrón Observador.
* *servicio-consultas* -> se expone una vista optimizada para lectura en `servicio-consultas/src/main/java`. Se actualiza únicamente a partir de eventos, adoptando el patrón CQRS para separar comandos y consultas.
* *servicio-orquestador* -> se coordina la creación de empleados y contratos en `servicio-orquestador/src/main/java` mediante un flujo SAGA basado en Spring StateMachine. Se comunica con los servicios correspondientes mediante Feign y publica el estado de la saga en Kafka.
* *API-gateway* -> se encamina todo el tráfico en `API-gateway/src/main/java` utilizando Spring Cloud Gateway. Las rutas se definen en `application.properties` y se balancea la carga gracias a la integración con Eureka.
* *servidor-para-descubrimiento* -> se ejecuta un servidor Eureka en `servidor-para-descubrimiento/src/main/java` para registrar cada microservicio.
* *servidor-para-monitoreo* -> se centraliza el monitoreo en `servidor-para-monitoreo/src/main/java` a través de Spring Boot Admin. Los servicios reportan sus métricas automáticamente.
**Importante**: todos los módulos se registran en Spring Boot Admin utilizando la propiedad `spring.boot.admin.client.instance.service-url`. Versiones previas usaban `service-base-url` y provocaban fallos intermitentes en la consola de monitoreo.
* *servicio-openapi-ui* -> se sirve la documentación en `servicio-openapi-ui/src/main/java` mediante ReDoc. Las especificaciones se obtienen desde el API Gateway.
* *comunes* -> se almacenan entidades y utilidades compartidas en `comunes/src/main/java`. Este módulo se utiliza como dependencia del resto.

Los microservicios se comunican principalmente por HTTP a través del API Gateway y de forma asíncrona con eventos en Kafka. Cada servicio persiste su estado en bases MariaDB y `servicio-consultas` mantiene proyecciones de lectura. Los servidores de descubrimiento y monitoreo completan la infraestructura para garantizar escalabilidad y observabilidad.
